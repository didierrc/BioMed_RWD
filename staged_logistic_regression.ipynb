{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c99b4510",
   "metadata": {},
   "source": [
    "# BioMed: Real World Data - Staged Logistic Regression Model\n",
    "\n",
    "---\n",
    "\n",
    "**Group:**\n",
    "- González Méndez, Alvaro ()\n",
    "- Reyes Castro, Didier Yamil (didier.reyes.castro@alumnos.upm.es)\n",
    "- Rodriguez Fernández, Cristina ()\n",
    "\n",
    "**Course:** BioMedical Informatics - 2025/26\n",
    "\n",
    "**Institution:** Polytechnic University of Madrid (UPM)\n",
    "\n",
    "**Date:** October 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Goals\n",
    "\n",
    "The goal of the assignment is to implement a staged logistic regression model with real-world biomedical data. The model will be used to rank LOINC documents based on their relevance to specific clinical queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee411b",
   "metadata": {},
   "source": [
    "## 0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3afab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018fb21",
   "metadata": {},
   "source": [
    "## 1 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "\n",
    "DATASET_FIRST_STAGE = 'data/first_stage_data.csv'\n",
    "DATASET_SECOND_STAGE = 'data/second_stage_data.csv'\n",
    "\n",
    "MODEL_1_PATH = 'first_stage_logistic_regression_model.joblib'\n",
    "MODEL_2_PATH = 'second_stage_logistic_regression_model.joblib'\n",
    "\n",
    "try:\n",
    "    df_first_stage = pd.read_csv(DATASET_FIRST_STAGE)\n",
    "    df_second_stage = pd.read_csv(DATASET_SECOND_STAGE)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c73eced",
   "metadata": {},
   "source": [
    "### 1.1 Part A: Train First Logistic Regression Model (Intra-Clue)\n",
    "\n",
    "The elementary clues taken into account for the first stage are: TF, IDF, is_in_component and is_in_system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcc82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = ['TF', 'IDF', 'is_in_component', 'is_in_system']\n",
    "target_1 = 'relevance'\n",
    "\n",
    "X1 = df_first_stage[features_1]\n",
    "Y1 = df_first_stage[target_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression default parameters: penalty='l2', C=1.0, solver='lbfgs'\n",
    "# solver can be changed to 'liblinear' as it is great for small datasets and binary\n",
    "# classification. Check: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "model_1 = LogisticRegression()\n",
    "model_1.fit(X1, Y1)\n",
    "\n",
    "# Save the trained model to a file\n",
    "# joblib.dump(model_1, MODEL_1_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934fdbb",
   "metadata": {},
   "source": [
    "### 1.2 Part B: Generate Second-Level Dataset\n",
    "\n",
    "1. Get Log-Odds from First Model (use the first dataset and predict with the model -> this will give you the log O(R/Ai) )\n",
    "2.  Sum up Log-Odds per Document (group by doc_id and sum the log-odds) -> Gives you the Z score per document.\n",
    "3. Complete the second stage dataset with the Z score (for those documents with 0 clues (N) fill Z with 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get log-Odds\n",
    "df_first_stage['log_odds'] = model_1.decision_function(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95afcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate Z score per document\n",
    "Z = df_first_stage.groupby(['doc_id', 'query_id'])['log_odds'].sum().reset_index()\n",
    "Z = Z.rename(columns={'log_odds': 'Z'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ca747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Complete the second stage dataset with the Z score (for those documents with 0 clues (N) fill Z with 0)\n",
    "df_second_stage = df_second_stage.merge(Z, on=['doc_id', 'query_id'], how='left')\n",
    "df_second_stage['Z'] = df_second_stage['Z'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e1b8d",
   "metadata": {},
   "source": [
    "### 1.3 Part C: Train Second Logistic Regression Model (Inter-Clue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_2 = ['Z', 'N']\n",
    "target_2 = 'relevance'\n",
    "\n",
    "X2 = df_first_stage[features_2]\n",
    "Y2 = df_first_stage[target_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LogisticRegression()\n",
    "model_2.fit(X2, Y2)\n",
    "\n",
    "# Save the trained model to a file\n",
    "# joblib.dump(model_2, MODEL_2_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f69bb",
   "metadata": {},
   "source": [
    "## 2 Retrieval\n",
    "\n",
    "Let's make the ranking of documents for a given query using the two-stage logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28925db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally, these structures should be generated from a large\n",
    "# biomedical knowledge base. They are hardcoded here for simplicity.\n",
    "THESAURUS = {\n",
    "    'glucose': ['glucose'],\n",
    "    'blood': ['blood', 'bld', 'serum', 'ser', 'plasma', 'plas'],\n",
    "    'bilirubin': ['bilirubin'],\n",
    "    'plasma': ['plasma', 'plas'],\n",
    "    'white blood cells': ['white blood cells', 'wbc', 'leukocyte', 'lymphocyte', 'monocyte'],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Ideally, this mapping should be generated at runtime from the THESAURUS\n",
    "# This would be part of a large information retrieval module but it is\n",
    "# out of scope for this example.\n",
    "QUERY_TO_CONCEPTS = {\n",
    "    'glucose in blood': ['glucose', 'blood'],\n",
    "    'bilirubin in plasma': ['bilirubin', 'plasma'],\n",
    "    'white blood cells count': ['white blood cells'],\n",
    "}\n",
    "\n",
    "# Getting our Corpus\n",
    "CORPUS_PATH = 'data/loinc_docs.csv'\n",
    "try:\n",
    "    df_corpus = pd.read_csv(CORPUS_PATH)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading corpus dataset: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410e32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def check_match(field, concept_terms):\n",
    "    return any(term.lower() in field.lower() for term in concept_terms)\n",
    "\n",
    "def check_appears_in_document(loinc_doc, concept_terms):\n",
    "    return check_match(loinc_doc['long_common_name'], concept_terms) or \\\n",
    "        check_match(loinc_doc['component'], concept_terms) or \\\n",
    "        check_match(loinc_doc['system'], concept_terms)\n",
    "\n",
    "def build_first_stage_dataset(concepts):\n",
    "    \n",
    "    dataset_1_rows = []\n",
    "    for concept in concepts:\n",
    "        concept_terms = THESAURUS.get(concept)\n",
    "        \n",
    "        for _, loinc_doc in df_corpus.iterrows():\n",
    "\n",
    "            # Check if any of the terms for the concept are in the document\n",
    "            if check_appears_in_document(loinc_doc, concept_terms):\n",
    "\n",
    "                # If there is a match, compute TF and other features\n",
    "                tf = sum(loinc_doc['long_common_name'].lower().count(term.lower()) for term in concept_terms)\n",
    "                idf = math.log(len(df_corpus) / sum(1 for _, doc in df_corpus.iterrows() if check_appears_in_document(doc, concept_terms)))\n",
    "                is_in_component = int(check_match(loinc_doc['component'], concept_terms))\n",
    "                is_in_system = int(check_match(loinc_doc['system'], concept_terms))\n",
    "\n",
    "                dataset_1_rows.append({\n",
    "                    'loinc_num': loinc_doc['loinc_num'],\n",
    "                    'concept': concept,\n",
    "                    'TF': tf,\n",
    "                    'IDF': idf,\n",
    "                    'is_in_component': is_in_component,\n",
    "                    'is_in_system': is_in_system,\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(dataset_1_rows)\n",
    "\n",
    "def build_second_stage_dataset(df, query):\n",
    "    \n",
    "    # Calculate Z score per document\n",
    "    Z_query = df.groupby(['loinc_num'])['log_odds'].sum().reset_index()\n",
    "    Z_query = Z_query.rename(columns={'log_odds': 'Z'})\n",
    "\n",
    "    # Calculate N (number of unique concepts) per document\n",
    "    N_query = df.groupby('loinc_num')['concept'].nunique().reset_index()\n",
    "    N_query = N_query.rename(columns={'concept': 'N'})\n",
    "\n",
    "    # Merge Z and N dataframes\n",
    "    df_second_stage = pd.merge(Z_query, N_query, on='loinc_num', how='left')\n",
    "\n",
    "    # Fill NaN values with 0\n",
    "    df_second_stage['Z'] = df_second_stage['Z'].fillna(0)\n",
    "    df_second_stage['N'] = df_second_stage['N'].fillna(0)\n",
    "\n",
    "    return df_second_stage\n",
    "\n",
    "def rank_documents(query):\n",
    "\n",
    "    # 1. Get the concepts for the query. Again this would be part of a larger\n",
    "    # information retrieval module.\n",
    "    concepts = QUERY_TO_CONCEPTS.get(query) \n",
    "\n",
    "    if not concepts:\n",
    "        print(f\"No concepts found for query: {query}\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Build dataset #1 for the query\n",
    "    df_first_stage_query = build_first_stage_dataset(concepts, query)\n",
    "\n",
    "    # 3. Get log-odds from first model\n",
    "    df_first_stage_query['log_odds'] = model_1.decision_function(df_first_stage_query[features_1])\n",
    "\n",
    "    # 4. Build second stage dataset\n",
    "    df_second_stage_query = build_second_stage_dataset(df_first_stage_query, query)\n",
    "\n",
    "    # 5. Predict relevance using second model\n",
    "    df_second_stage_query['final_score'] = model_2.decision_function(df_second_stage_query[features_2])\n",
    "\n",
    "    # 6. Rank documents based on final score\n",
    "    df_ranked = df_second_stage_query.sort_values(by='final_score', ascending=False)\n",
    "\n",
    "    return df_ranked[['loinc_num', 'long_common_name', 'final_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_list_1 = rank_documents(\"glucose in blood\")\n",
    "if ranked_list_1 is not None:\n",
    "    print(\"--- Top 5 Results for 'glucose in blood' ---\")\n",
    "    print(ranked_list_1.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
